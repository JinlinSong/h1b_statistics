{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jupyter notebook --browser chrome\n",
    "#$ pwd\n",
    "# /Users/jinlin_song/Desktop/Github/h1b_statistics/insight_testsuite/tests/test_1/input\n",
    "\n",
    "import sys\n",
    "\n",
    "# Get variables from sys\n",
    "# data_file = sys.argv[1]\n",
    "# occupation_file = sys.argv[2]\n",
    "# state_file = sys.argv[3]\n",
    "\n",
    "# Read data from input data path\n",
    "data_file = './insight_testsuite/tests/test_1/input/h1b_input.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H1B_CSV_dataset:\n",
    "    def __init__(self, data_file, sep = ';'):\n",
    "        self.value = True\n",
    "        self.data_input = []\n",
    "        try:\n",
    "            with open(data_file,'r',encoding=\"utf-8\") as f:\n",
    "                for row in f:\n",
    "                    self.data_input.append(row.strip('\\n').split(sep))\n",
    "        except:\n",
    "            print('Error: Not able to load data from given input file.')\n",
    "            self.value = False\n",
    "            ### sys.exit()\n",
    "            \n",
    "    ### csv validation method\n",
    "    def is_valid(self):\n",
    "        return self.value\n",
    "    \n",
    "    ### get H1B CSV dataset header\n",
    "    def data_header(self):\n",
    "        return self.data_input[0] if self.value else None\n",
    "    \n",
    "    ### get H1B CSV dataset without header\n",
    "    def data_set(self):\n",
    "        return self.data_input[1:] if self.value else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1B_CSV_dataset = H1B_CSV_dataset(data_file,sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "H1B_CSV_dataset.data_input\n",
    "H1B_CSV_dataset.is_valid()\n",
    "data_header = H1B_CSV_dataset.data_header()\n",
    "data_set = H1B_CSV_dataset.data_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_related_columns(data_set, data_header, state_column_name = 'WORKSITE_STATE',\n",
    "                            occupation_column_name = 'SOC_NAME',\n",
    "                            status_column_name = 'CASE_STATUS'):\n",
    "    \n",
    "    related_column_index = []\n",
    "    try:\n",
    "        state_index = data_header.index(state_column_name)\n",
    "        related_column_index.append(state_index)\n",
    "    except:\n",
    "        print('Error: Not able to find state_column_name, please specify correct state_column_name.')\n",
    "        return False\n",
    "    try:\n",
    "        occupation_index = data_header.index(occupation_column_name)\n",
    "        related_column_index.append(occupation_index)\n",
    "    except:\n",
    "        print('Error: Not able to find occupation_column_name, please specify correct occupation_column_name.')\n",
    "        return False\n",
    "    try:\n",
    "        status_index = data_header.index(status_column_name)\n",
    "        related_column_index.append(status_index)\n",
    "    except:\n",
    "        print('Error: Not able to find status_column_name, please specify correct status_column_name.')\n",
    "        return False\n",
    "    \n",
    "    ### extract related columns\n",
    "    H1B_dataset = [[e[i].strip('\"') for i in related_column_index] for e in data_set]\n",
    "    \n",
    "    ### remove non-certified records\n",
    "    H1B_dataset_certified = [e[:2] for e in H1B_dataset if e[2] == 'CERTIFIED']\n",
    "    \n",
    "    return H1B_dataset_certified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H1B_dataset_certified = extract_related_columns(data_set, data_header, state_column_name = 'WORKSITE_STATE',\n",
    "                            occupation_column_name = 'SOC_NAME',\n",
    "                            status_column_name = 'CASE_STATUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['WA', 'SOFTWARE DEVELOPERS, APPLICATIONS'],\n",
       " ['CA', 'ACCOUNTANTS AND AUDITORS'],\n",
       " ['TX', 'DATABASE ADMINISTRATORS'],\n",
       " ['DE', 'SOFTWARE DEVELOPERS, APPLICATIONS'],\n",
       " ['AL', 'SOFTWARE DEVELOPERS, APPLICATIONS'],\n",
       " ['FL', 'SOFTWARE DEVELOPERS, APPLICATIONS'],\n",
       " ['FL', 'SOFTWARE DEVELOPERS, APPLICATIONS'],\n",
       " ['MD', 'COMPUTER SYSTEMS ANALYST'],\n",
       " ['NJ', 'COMPUTER OCCUPATIONS, ALL OTHER'],\n",
       " ['GA', 'SOFTWARE DEVELOPERS, APPLICATIONS']]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H1B_dataset_certified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class H1B_stat:\n",
    "    def __init__(self, H1B_dataset_certified):\n",
    "        self.H1B_dataset_certified = H1B_dataset_certified\n",
    "        self.total_records = len(H1B_dataset_certified)\n",
    "\n",
    "    def occupation_stat(self):\n",
    "        occupation_stat_dict = {}\n",
    "        for record in self.H1B_dataset_certified:\n",
    "            if record[1] in occupation_stat_dict:\n",
    "                occupation_stat_dict[record[1]] += 1\n",
    "            else:\n",
    "                occupation_stat_dict[record[1]] = 1\n",
    "        \n",
    "        ### sort occupation_stat_dict\n",
    "        occupation_stat_set = sorted(occupation_stat_dict.items(), key = lambda kv: kv[1], reverse = True)[:10]\n",
    "\n",
    "        ### add percentaga    \n",
    "        occupation_stat_set = [[e[0], e[1], float(round(100*e[1]/self.total_records, 1))] for e in occupation_stat_set]    \n",
    "\n",
    "        return occupation_stat_set\n",
    "    \n",
    "    def state_stat(self):\n",
    "        state_stat_dict = {}\n",
    "        for record in self.H1B_dataset_certified:\n",
    "            if record[0] in state_stat_dict:\n",
    "                state_stat_dict[record[0]] += 1\n",
    "            else:\n",
    "                state_stat_dict[record[0]] = 1\n",
    "                \n",
    "        ### sort state_stat_dict\n",
    "        state_stat_set = sorted(state_stat_dict.items(), key = lambda kv: kv[1], reverse = True)[:10]\n",
    "\n",
    "        ### add percentaga    \n",
    "        state_stat_set = [[e[0], e[1], float(round(100*e[1]/self.total_records, 1))] for e in state_stat_set]    \n",
    "\n",
    "        return state_stat_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H1B_stat = H1B_stat(H1B_dataset_certified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_stat = H1B_stat.state_stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_stat = H1B_stat.occupation_stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['SOFTWARE DEVELOPERS, APPLICATIONS', 6, 60.0],\n",
       " ['ACCOUNTANTS AND AUDITORS', 1, 10.0],\n",
       " ['DATABASE ADMINISTRATORS', 1, 10.0],\n",
       " ['COMPUTER SYSTEMS ANALYST', 1, 10.0],\n",
       " ['COMPUTER OCCUPATIONS, ALL OTHER', 1, 10.0]]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occupation_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_data(dataset, path, data_type):\n",
    "    file_header = \"NUMBER_CERTIFIED_APPLICATIONS;PERCENTAGE\"\n",
    "    with open(path, 'w') as f:\n",
    "        if data_type == 'TOP_OCCUPATIONS':\n",
    "            file_header = \"TOP_OCCUPATIONS;\" + file_header\n",
    "        elif data_type == 'TOP_STATES':\n",
    "            file_header = \"TOP_STATES;\" + file_header\n",
    "        else:\n",
    "            print(\"Error: Invalid data_type, please specify data_type as 'TOP_OCCUPATIONS' or 'TOP_STATES'.\")\n",
    "            return False\n",
    "        \n",
    "        ### write header to the output file\n",
    "        f.write(file_header + '\\n')\n",
    "        \n",
    "        ### convert integer to string\n",
    "        dataset_output = [[e[0], str(e[1]), str(e[2]) + '%'] for e in dataset]\n",
    "        \n",
    "        ### write data to the output file\n",
    "        for item in dataset_output:\n",
    "            f.write(\";\".join(item) + '\\n')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_occupation_stat = \"/Users/jinlin_song/Desktop/Github/h1b_statistics/top_10_occupations.txt\"\n",
    "path_state_stat = \"/Users/jinlin_song/Desktop/Github/h1b_statistics/top_10_states.txt\"\n",
    "\n",
    "write_data(state_stat, path_state_stat, data_type = 'TOP_STATES')\n",
    "write_data(occupation_stat, path_occupation_stat, data_type = 'TOP_OCCUPATIONS')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
